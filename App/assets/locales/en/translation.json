{
  "home": "Home",
  "data": "Data",
  "use": "Use",
  "learn": "Learn",
  "Train": "Train",
  "Test": "Test",
  "no-py-env": "Python enviornment not found!",
  "use-existing": "Use Existing",
  "new-venv":"New VENV",
  "choose-image-folder" : "Choose Image Folder",
  "choоse-labels" : "Choose Labels",
  "create-labels" : "Create Labels",
  "captioning" : "Captioning",
  "image-classification": "Image Classification",
  "object-detection": "Object Detection",
  "type": "Type",
  "overview-button": "Overview",
  "finish-button": "Finish",
  "fill-manually": "Fill Manually",
  "no-labels": "No Labels?",
  "delete-rows": "Delete Rows",
  "name-dataset": "Dataset Name",
  "finish": "Finish",
  "tabular": "Тabular",
  "image": "Image",
  "text": "Text",
  "homepage": "Homepage",
  "new-datasets": "New Datasets",
  "create-tabular-dataset": "Create Tabular Dataset",
  "chosen-images": "Images chosen",
  "chosen-labels": "Labels chosen",
  "no-images-found": "No images found",
  "no-labels-found": "No labels found",
  "add-label": "Add Labels",
  "enter-label": "Enter Label",
  "missing-width": "Missing Width",
  "missing-height": "Missing Height",
  "missing-name": "Missing Name",
  "width": "Width",
  "height": "Height",
  "name": "Name",
  "delete-image": "Delete Image",
  "create-model": "Create Model",
  "create-dataset": "Create Dataset",
  "dataset-type": "Dataset Type",
  "dataset": "Dataset",
  "hidden-layers": "Hidden layers",
  "add-layer": "Add Layer",
  "activation-function": "Activation function",
  "expected-number-between": "Expected number between",
  "expected-whole-number-between": "Expected whole number between",
  "and": "and",
  "missing-layers": "Missing Layers",
  "new-dataset": "New Dataset",
  "select-file": "Selected File",
  "make-model": "Make Model",
  "records": "Records",
  "image-data": "Image Data",
  "no-datasets-found": "No Datasets Found",
  "learn-ai": "Learn AI",
  "ml-introduction": " to the learning page focused on essential properties in machine learning (ML). In this module, we'll delve into key properties that significantly impact the training and performance of ML models. Understanding these properties is fundamental for building effective and robust ML systems.",
  "neural-network": "Neural network",
  "neural-network-text": " is a computer system inspired by the structure and functioning of the human brain. It's used for solving problems that are too complex for traditional algorithms. Neural networks consist of interconnected nodes, called neurons, arranged in layers. These networks can learn patterns and relationships from data, making them powerful tools for tasks like image recognition, language translation, and predictive analysis.",
  "components-of-neural-network": "Components of a Neural Network",
  "neurons": "Neurons",
  "neurons-text": " are the basic building blocks of a neural network. They receive input, process it, and produce an output. Neurons are organized into layers: input layer, hidden layers, and output layer.",
  "layers": "Layers",
  "dense": "Dense",
  "dense-text": " layer, also known as a fully connected layer, is a fundamental building block in neural networks. Imagine it as a layer where every neuron is connected to every neuron in the previous and next layers. Each neuron in a dense layer receives input from all neurons in the previous layer and produces an output value. Dense layers are commonly used for learning patterns in data and making predictions. For example, in a simple neural network for image classification, the first dense layer might receive flattened pixel values of an image as input and learn to recognize patterns in the data, such as edges or shapes.",
  "dropout": "Dropout",
  "dropout-text": " is a regularization technique used to prevent overfitting in neural networks. It works by randomly dropping a certain percentage of neurons (along with their connections) during training, effectively forcing the network to learn more robust and generalizable features. Dropout helps prevent the network from relying too heavily on specific neurons or features, making it less likely to memorize the training data and better able to generalize to unseen data. For example, in a dropout layer with a dropout rate of 0.5, each neuron has a 50% chance of being temporarily dropped during training.",
  "conv2D": "Convolutional 2D",
  "conv2D-text": " layer is a fundamental component of convolutional neural networks (CNNs), which are widely used for tasks like image recognition and object detection. Conv2D layers apply a convolution operation to the input data, sliding a small filter (also known as a kernel) across the input image to extract features. This process helps the network learn hierarchical representations of the input data, capturing patterns at different levels of abstraction. For example, in image classification, the first Conv2D layer might learn low-level features like edges and textures, while subsequent layers learn higher-level features like shapes and objects.",
  "max-poling2D": "MaxPooling2D",
  "max-poling2D-text": " is a pooling operation commonly used in CNNs to reduce the spatial dimensions of feature maps while retaining important information. It works by dividing the input feature map into non-overlapping regions and retaining only the maximum value within each region. This reduces the computational complexity of the network and helps prevent overfitting by reducing the number of parameters. For example, in an image classification CNN, MaxPooling2D layers are typically used to downsample feature maps after convolutional layers, reducing their spatial resolution while preserving the most relevant information.",
  "batch-size": "Batch Size",
  "batch-size-text": " determines the number of training examples used in one iteration of training. Larger batch sizes can speed up training but require more memory, while smaller batch sizes can lead to more stable training. Adjust batch size based on hardware constraints and dataset characteristics to achieve optimal training performance.",
  "dataset-split": "Dataset split",
  "training": "Training",
  "training-text": " set is the set of data used to train the model. It comprises a large portion of the available data and is the basis for model parameter estimation. The training set must include all the possible inputs the model can process. For example, if your model must classify pictures of cats and dogs, the training set must include both cats and dogs.",
  "validation": "Validation",
  "validation-text": " set, sometimes called the development set, is an intermediary between the training and test sets. Its primary purpose is to fine-tune the model's hyperparameters and assess its performance during training. Unlike the test set, the validation set is used iteratively during the model development. By evaluating the model's performance on the validation set, we can make informed decisions about adjusting hyperparameters, selecting the best-performing model, or identifying potential overfitting or underfitting issues.",
  "testing": "Testing",
  "testing-text": " set is a separate subset of the data withheld during the training phase. It is an unbiased benchmark to evaluate the model's performance after training. The test set simulates real-world data that the model is likely to encounter in production. By assessing the model's performance on previously unseen examples, we can gauge its ability to generalize and make accurate predictions on new, unseen data.",
  "weights-bias": "Weights and Bias",
  "weights-bias-text": " has a weight associated with it, which determines the strength of the connection. The network learns by adjusting these weights based on the input data. Additionally, each neuron has a bias term that helps control the output of that neuron.",
  "target": "Target",
  "target-text": " also known as the target variable or dependent variable, is the variable that the model aims to predict or estimate based on the input features.",
  "learning-rate": "Learning Rate",
  "learning-rate-text": " controls the step size at which the model's parameters are updated during training. Proper selection of the learning rate is crucial for achieving fast convergence without overshooting or getting stuck in local minima. Experiment with different learning rates and consider using adaptive learning rate algorithms for improved performance.",
  "epoch": "Epoch",
  "epoch-text": " represents one complete iteration through the entire training dataset, where the model updates its parameters based on the training examples to minimize the loss function. During each epoch, the dataset is divided into batches, and the model sequentially processes each batch, performing forward and backward propagation to compute gradients and update parameters using an optimization algorithm such as gradient descent. Training for multiple epochs allows the model to iteratively learn from the dataset, improving its performance over time, but it's crucial to monitor for overfitting by evaluating performance on a separate validation dataset. Adjusting the number of epochs is essential to achieve optimal generalization performance without overfitting.",
  "datasets": "Dataset",
  "dataset-bold" : "Datasets",
  "datasets-introduction": " are structured collections of data used for analysis, research, or training machine learning models. They consist of individual data points, each representing an observation or sample, along with attributes or features describing those samples.",
  "tabular-bold" : "Tabular  data",
  "tabular-subtext-1": ", often likened to a spreadsheet, is structured in rows and columns. Each row represents an individual observation, while each column denotes a specific attribute or feature associated with that observation.",
  "tabular-subtext-2": "In simpler terms, think of it as an organized table where each row describes something, like a customer's information or a product's characteristics. For instance, in a customer database, each row might represent a different customer, with columns containing details such as their age, gender, and purchase history.",
  "tabular-subtext-3": "Labels in tabular datasets typically indicate what we're trying to predict or understand, like whether a customer will make a purchase or not. This type of data is commonly used in predictive modeling and decision-making tasks, making it a fundamental aspect of machine learning for analyzing and understanding structured information.",
  "classification-bold": "Image classification",
  "classification-subtext-1": " involves teaching a computer to recognize and assign labels to images based on their contents. Imagine teaching a child to differentiate between different animals in a picture bo ok - it's a similar concept.",
  "classification-subtext-2": "In image classification datasets, images are categorized into predefined classes or categories, such as 'dog', 'cat, or 'car.' These datasets are crucial for training algorithms to automatically recognize and classify objects in images, enabling applications like facial recognition, autonomous driving, and medical imaging. Labels in image classification datasets specify the correct category or class for each image, guiding the learning process and enabling the model to make accurate predictions.",
  "classification-subtext-3": "In programming and machine learning, understanding image classification datasets is a fundamental step towards building models that can interpret visual information effectively.",
  "detection-bold": "Object detection",
  "detection-subtext-1": " goes beyond simple classification by identifying and locating multiple objects within an image. It's like having a computer scan a picture and draw boxes around different items, indicating what they are and where they're located.",
  "detection-subtext-2": "In datasets for object detection tasks, images are annotated with bounding boxes around objects of interest, along with labels specifying the class of each object. For instance, in a street scene, objects like cars, pedestrians, and traffic lights may be annotated with bounding boxes and corresponding labels.",
  "detection-subtext-3": "Object detection is crucial for applications like surveillance, autonomous navigation, and augmented reality, as it enables machines to perceive and interact with their surroundings in a detailed manner.",
  "captioning-bold": "Image captioning",
  "captioning-subtext-1": " combines computer vision and natural language processing to generate descriptive captions for images automatically. It's like teaching a computer to describe what it sees in a picture, just like a person would.",
  "captioning-subtext-2": "In image captioning datasets, each image is paired with one or more human-generated captions, providing textual descriptions of the objects, actions, and scenes depicted in the images. These datasets enable researchers and developers to train algorithms that can understand and communicate visual information effectively. Labels in image captioning datasets consist of the textual descriptions corresponding to each image, guiding the model in learning to generate accurate and meaningful captions.",
  "captioning-subtext-3": "In programming and machine learning, grasping the concept of image captioning datasets lays the groundwork for creating AI systems capable of understanding and describing visual content.",
  "models": "Models",
  "setup": "Setup",
  "setup-introduction": "This page will teach you how to setup the python enviornment which will run all of the python code used for creating and training the models. First select weather you will use your CPU or GPU for creating and training the models. Using the CPU is simpler but is also slower. On the other hand using the GPU is much faster but is also harder to set up.",
  "cpu-introduction": "If you want to use your CPU you can either follow this guide which uses Python to create the enviornment or the GPU guide, which uses miniconda for the enviornment, and skipping step.",
  "gpu-setup":"GPU setup",
  "system-requirements":"System Requirements",
  "or-higher":"or higher",
  "python-version":"If Python is not already installed on your system, download and install a version between Python 3.8 and Python 3.11 from the ",
  "official-python-website": "Official Python Website",
  "check-python-path": " Make sure to check the option to add Python to your system PATH during installation.",
  "open-command-prompt": "Open Command Prompt",
  "press":"Press ",
  "type-cmd": " type ",
  "press-enter": "and press Enter to open the Command Prompt.",
  "create-virtual-env": "Create a Virtual Environment",
  "activate-virtual-env": "Activate the Virtual Environment",
  "active-virtual-env": "Activate the virtual environment by running the following command",
  "install-necessary-libraries": "Install necessary libraries",
  "once-activated-env":"Once the virtual environment is activated, install the necessary libraries using pip",
  "select-python-executable": "Selecting the python executable",
  "select-python-executable-subinfo-1":"Go to the settings on the bottom left",
  "select-python-executable-subinfo-2": "Select the path to the python executable of the environment you just created",
  "do-not-run-python-env": "If you dont know what the path to the environment is you can run this",
  "default-path-text": "By default the path should be",
  "instructions-conclusion": "If followed the instructions to this point the enviornment should be set up and you should have the ability to train your own models. You can close everything you had to open and can proceed with the",
  "tutorial": "Tutorial",
  "instructions-conclusion-rest-part": "which will guide you on how to create and use your own models . In case you faced any issues you can check the full",
  "installation-guide": "installation guide",
  "install-microsoft-visual-redistributable": "Install Microsoft Visual C++ Redistributable",
  "go-to": "Go to the",
  "install-VS-subinstruction-1": "Scroll down the page to the Visual Studio 2015, 2017 and 2019 section.",
  "install-VS-subinstruction-2": "Download and install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 for your platform.",
  "install": "Install",
  "download": "Download the",
  "double-click-instruction": "Double-click the downloaded file and follow the instructions on the screen.",
  "open": "Open",
  "press-enter-gpu": "and press Enter to open the",
  "create-conda-env": "Create a conda environment",
  "create-conda-env-instruction-1": "Create a new conda environment named tf by running the following command",
  "activate-env": "Activate the environment",
  "update": "Update",
  "run-following-command-gpu": "Run the following command in order to setup GPU support",
  "getting-started": "Getting started",
  "welcome": "Welcome",
  "weights-bias-start":"Each connection between neurons",
  "target-start":"In machine learning (ML), the target,",
  "epoch-start": "In machine learning, an epoch",
  "learning-rate-start":"Learning rate",
  "no-python-title": "No Python",
  "no-python-message": "You haven't setup python. You can see how to do that by going to the setup section.",
  "no-models-found": "No models were found",
  "new-model": "New model",
  "homepage-text1-part1": "First step ",
  "homepage-text1-part2":"you need to take is to insert some data set in the form of a table or pictures by going to 'Data' and selecting 'Import'.",
  "homepage-text2-part1": "Second step ",
  "homepage-text2-part2":"is to make a model based on a dataset you made before by going to 'Models' and then to 'Create'.",
  "homepage-text3-part1": "Third step ",
  "homepage-text3-part2":" is to choose which model you want to train by selecting the 'Train Model' button.",
  "train-model": "Train",
  "homepage-text4-part1": "Last Step ",
  "homepage-text4-part2": "is now that you are done with the training, you can test it and see the results by going to 'Use'.",
  "use-model":"Use Model",
  "homepage-introduction": "in our application, where anyone who is familiar with programming or more precisely with artificial intelligence can take advantage of the features of our program. Here you can create and train models that you can use in making apps or programs that you make. Here you can input and train information in the form of tables or pictures. You can quickly, easily and efficiently make models using machine learning(ML).",
  "start-with-easy-step": "Start with some easy steps",
  "go-to-setup": "Go to Setup",
  "import": "Import",
  "view":"View",
  "not-trained":"Not Trained",
  "create": "Create",
  "epochs": "Epochs",
  "select-model-options": "Select Model Options",
  "model-trained-for":"Model Trained For",
  "integrate-table-text":"This section contains code which can be used to integrate the model into your own projects. You need to save the model and then import it into code like this",
  "tabular data": "Tabular data",
  "accuracy": "Accuracy",
  "edit": "Edit",
  "delete": "Delete",
  "model-type": "Model Type",
  "model": "Model",
  "test-model": "Test Model",
  "integrate-model":"Integrate Model",
  "result": "Result",
  "save-model": "Save Model",
  "python":"Python",
  "settings-title":"Settings",
  "python_exe_path": "Path to python executable",
  "creating-model-title": "Creating Model",
  "creating-model-text":"Creating the model may take some time",
  "python-error-title":"Python Error",
  "python-error-message":"There was an error while running the python code. Make sure you have set up everything correctly. You might have forgotten to download the libraries.",
  "create-file-error-title": "Create file error",
  "create-file-error-message": "There was an error when trying to create a file.",
  "model-created-title":"Model created successfully",
  "model-created-message":"The model was created successfully. You can proceed with the training.",
  "model-download-started-title": "Download started",
  "model-download-started-message": "Downloading the model has started.",
  "apply":"Apply",
  "cancel": "Cancel",
  "how-to-setup-python-enviornment": "How to setup the python enviornment?",
  "data-type":"Data type",
  "include":"Include",
  "missing-values-title":"Some values are missing",
  "missing-values-text": "Some values from the dataset are missing. What do you want to do with them?",
  "has-headers": "Has Headers",
  "name-missing": "Name is missing",
  "create-tabular-dataset-warning":"The data should contain only numbers and latin letters, without commas and without NULL",
  "read-dataset-file-error-title":"Dataset file not found",
  "read-dataset-file-error-message":"Dataset file wasn't found. Maybe it was deleted.",
  "create-env-title":"Creating python enviornment",
  "train-title":"Training",
  "starting-training":"Starting the training process",
  "success-training-title":"Successfully trained",
  "success-training-message":"Training was successful.",
  "records-per-graph":"Records Per Graph",
  "delete-dataset-success-title":"Success",
  "delete-dataset-success-message":"Successfully Deleted The Dataset",
  "delete-model-success-title":"Success",
  "delete-model-success-message":"Successfully Deleted The Model"
}